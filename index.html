<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<link rel="alternate" href="/default" title="Mr.Thirteen's blog"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.11.0">
<link rel="canonical" href="https://at-fieldless.github.io/">

<link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css"><link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css">
<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.11.0">

<script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
<script>
  window.config = {"leancloud":"app_id:Ft6e3NGMakjJA8863I2S0Njs-gzGzoHsz app_key:0FzGh29Jey21Jw3XXnTI4TvJ","toc":true,"fancybox":true,"pjax":true,"latex":false};
</script>

    <title>Mr.Thirteen's blog</title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Mr.Thirteen's blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list"><a href="/">
        <li class="mobile-menu-item">首页
          </li>
      </a><a href="/archives/">
        <li class="mobile-menu-item">归档
          </li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签
          </li>
      </a></ul>
</nav>
<div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Mr.Thirteen's blog</a>
</div>

<nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item">
          <a class="menu-item-link" href="/">
            首页
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            归档
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/tags/">
            标签
            </a>
        </li>
      </ul></nav>
</header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content"><section id="posts" class="posts"><article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2020/08/29/两阶段提交协议介绍——以Flink-Kafka-Producer为例/">两阶段提交协议介绍——以Flink Kafka Producer为例</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-08-29
        </span></div>
    </header>

    <div class="post-content"><h2 id="Exactly-once-语义"><a href="#Exactly-once-语义" class="headerlink" title="Exactly once 语义"></a>Exactly once 语义</h2><p>在分布式系统中对消息的处理有三个层次，分别是<strong>At-most-once</strong>（最多一次），<strong>At-least-once</strong>（至少一次）, <strong>Exactly-once</strong>（精确一次）。</p>
<p>从字面意思想必大家都知道，Exactly-once语义是这三个中最好的，既能保证每条信息都被处理过一次，而且能让结果最为正确。</p>
<p>可是对于一个分布式系统来说，出现异常的情况是非常常见的，诸如网络抖动造成消息丢失，集群中一台集器突然出现问题，无法继续处理信息，等等。</p>
<p>所以想要实现Exactly-once并不是一件容易的事。</p>
<h2 id="Flink-内部的-Exactly-once"><a href="#Flink-内部的-Exactly-once" class="headerlink" title="Flink 内部的 Exactly-once"></a>Flink 内部的 Exactly-once</h2><p>在 Flink 内部通过 checkpoint 机制来确保在内部处理时的 Exactly-once。</p>
<p>每次 checkpoint 时，都会记录当前系统所有算子的状态以及消费位置。因此当系统出现异常或重启时，就可以恢复到上次的位置重新开始运行，就好像问题从来没有发生一样。有关于 checkpoint 的内容，请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/concepts/stateful-stream-processing.html#checkpointing" target="_blank" rel="noopener">Flink checkpoint介绍</a>。本篇文章就不再进行赘述了。</p>
<p>可尽管Flink 内部通过 checkpoint 实现了 Exactly-once 的消费语义，但一个Flink程序往往需要和外部系统进行交互，进行数据的写入。因此该如何做到端到端的 Exactly-once 呢？这就要引出两阶段提交协议了。</p>
<h2 id="什么是两阶段提交协议"><a href="#什么是两阶段提交协议" class="headerlink" title="什么是两阶段提交协议"></a>什么是两阶段提交协议</h2><p>两阶段提交协议是为了分布式系统进行事务提交所产生的。其算法思路可以概括为: 参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。</p>
<p>二阶段是指:  第一阶段 - 请求阶段(表决阶段)     第二阶段 - 提交阶段(执行阶段)</p>
<p>(1) 请求阶段(表决)：</p>
<p>事务协调者通知每个参与者准备提交或取消事务，然后进入表决过程，参与者要么在本地执行事务，写本地的redo和undo日志，但不提交。</p>
<p>完成后，参与者将告知协调者自己的决策: 同意(事务参与者本地作业执行成功)或取消（本地作业执行故障）。</p>
<p>(2) 提交阶段(执行):</p>
<p>在该阶段，写调整将基于第一个阶段的投票结果进行决策: 提交或取消，</p>
<p>当且仅当所有的参与者同意提交事务，协调者才通知所有的参与者提交事务，否则协调者将通知所有的参与者取消事务。</p>
<p>参与者在接收到协调者发来的消息后将执行响应的操作。</p>
<h2 id="Flink-对两阶段协议的支持"><a href="#Flink-对两阶段协议的支持" class="headerlink" title="Flink 对两阶段协议的支持"></a>Flink 对两阶段协议的支持</h2><p>让我们通过一个简单的例子，来说明Flink是怎么实现两阶段提交协议的。<br><img src="https://flink.apache.org/img/blog/eo-post-graphic-1.png" alt="图1-1"><br>上图是一个简单的ETL的示例，Flink先从kafka读取数据，通过Window来进行数据的聚合，最后把数据再写回Kafka。</p>
<p><img src="https://flink.apache.org/img/blog/eo-post-graphic-2.png" alt="图1-2"><br>当需要进行checkpoint时，JobManager向数据源插入一个barrier。</p>
<p><img src="https://flink.apache.org/img/blog/eo-post-graphic-3.png" alt="图1-3"><br>回忆一下，之前Flink是如何实现内部状态的Exactly-once的。1.当barrier流入每个算子时，算子会把自己的状态存入预先设定的state backend中并通知JobManager。2.等到所有算子都完成状态存储时，JobManager也即标记本次checkpoint成功。这两步是不是能和两阶段提交协议中的请求阶段、提交阶段相呼应呢？答案自然不言而喻。</p>
<p><img src="https://flink.apache.org/img/blog/eo-post-graphic-4.png" alt="图1-4"><br>当然这一切在Flink内部是已实现完毕的，但如果有外部状态呢？就像要写入数据到Kafka中，每个partition的offset管理是由kafka自己实现的，Flink并不能很好的在原先的checkpoint实现中进行管理。</p>
<p>因此如果要实现端到端的exactly-once需要外部系统也能支持事务性的操作。</p>
<h2 id="kafka-对两阶段协议的支持"><a href="#kafka-对两阶段协议的支持" class="headerlink" title="kafka 对两阶段协议的支持"></a>kafka 对两阶段协议的支持</h2><h3 id="kafka消息的幂等性"><a href="#kafka消息的幂等性" class="headerlink" title="kafka消息的幂等性"></a>kafka消息的幂等性</h3><p>在消息系统中，经常出现的一种情况是由于网络延迟等问题，发送方没能收到ack信息，为了保证正确性，发送方会进行一次retry。而如果这时候网络又恢复了，接收方就等于收到了两次消息。</p>
<p>这种情况在某些场景无法正确处理，可能会出现很大的问题，就比如金融领域的订单信息，就会造成最后对账内容不正确。</p>
<p>为了实现幂等性，kafka实现了一套类似于tcp-ip协议机制。</p>
<p>在每次发送的信息中加入Producer ID（即PID）和Sequence Number。每个新的Producer在初始化的时候会被分配一个唯一的PID，该PID对用户完全透明而不会暴露给用户。</p>
<p>Producer发送每条消息&lt;Topic, Partition&gt;对于Sequence Number会从0开始单调递增，broker端会为每个&lt;PID, Topic, Partition&gt;维护一个序号，每次commit一条消息此序号加一，对于接收的每条消息，如果其序号比Broker维护的序号（即最后一次Commit的消息的序号）大1以上，则Broker会接受它，否则将其丢弃：</p>
<ul>
<li><p>序号比Broker维护的序号大1以上，说明存在乱序。</p>
</li>
<li><p>序号比Broker维护的序号小，说明此消息以及被保存，为重复数据。</p>
</li>
</ul>
<h3 id="kafka事务"><a href="#kafka事务" class="headerlink" title="kafka事务"></a>kafka事务</h3><p>单单实现了消息的幂等性还不够。在使用kafka时经常出现的场景是一个producer对多个topic和多个partition进行写操作。</p>
<p>因此这种操作希望能具有原子性，要么所有信息都成功写入，要么就全部失败。</p>
<p>为此kafka 0.11版本在原先的架构中引入了下图右边部分的内容。Transaction id和Transaction Coordinator。</p>
<p><img src="https://cdn.confluent.io/wp-content/uploads/transactions-1-1024x693.png" alt="图1-5"></p>
<p>每次Producer要进行事务操作时，都需要注册一个Transaction id，相同的Transaction id可以进行复用，不过一旦同一个Transaction id被新的producer使用了，老的id对应的producer再发送消息就不会再被接受了。Transaction Coordinator会通过记录一个单调递增的epoch变量来确保接收最新的producer信息。</p>
<p>通过上图，我们可以看到相比之前版本kafka发送消息来说，它还需要在Transaction Coordinator中进行日志记录和更新日志信息。只有当本次事务的t.id的状态变成committed时，这次事务才算成功。有关事务的更详细内容可以参考<a href="https://www.confluent.io/blog/transactions-apache-kafka/" target="_blank" rel="noopener">kafka事务介绍</a></p>
<h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><p>在 Flink 中给用户提供了<strong>TwoPhaseCommitSinkFunction</strong>接口，其中重要的三个方法：</p>
<ul>
<li>initializeState：事务的开始</li>
<li>snapshotState：两阶段协议的请求阶段</li>
<li>notifyCheckpointComplete：两阶段协议的执行阶段</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">TwoPhaseCommitSinkFunction</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initializeState</span><span class="params">(FunctionInitializationContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		state = context.getOperatorStateStore().getListState(stateDescriptor);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">boolean</span> recoveredUserContext = <span class="keyword">false</span>;</span><br><span class="line">    <span class="comment">//如果是从上一个检查点恢复</span></span><br><span class="line">		<span class="keyword">if</span> (context.isRestored()) &#123;</span><br><span class="line">			LOG.info(<span class="string">"&#123;&#125; - restoring state"</span>, name());</span><br><span class="line">			<span class="keyword">for</span> (State&lt;TXN, CONTEXT&gt; operatorState : state.get()) &#123;</span><br><span class="line">				userContext = operatorState.getContext();</span><br><span class="line">				List&lt;TransactionHolder&lt;TXN&gt;&gt; recoveredTransactions = operatorState.getPendingCommitTransactions();</span><br><span class="line">				List&lt;TXN&gt; handledTransactions = <span class="keyword">new</span> ArrayList&lt;&gt;(recoveredTransactions.size() + <span class="number">1</span>);</span><br><span class="line">				<span class="keyword">for</span> (TransactionHolder&lt;TXN&gt; recoveredTransaction : recoveredTransactions) &#123;</span><br><span class="line">					<span class="comment">// If this fails to succeed eventually, there is actually data loss</span></span><br><span class="line">					recoverAndCommitInternal(recoveredTransaction);</span><br><span class="line">					handledTransactions.add(recoveredTransaction.handle);</span><br><span class="line">					LOG.info(<span class="string">"&#123;&#125; committed recovered transaction &#123;&#125;"</span>, name(), recoveredTransaction);</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				&#123;</span><br><span class="line">					TXN transaction = operatorState.getPendingTransaction().handle;</span><br><span class="line">					recoverAndAbort(transaction);</span><br><span class="line">					handledTransactions.add(transaction);</span><br><span class="line">					LOG.info(<span class="string">"&#123;&#125; aborted recovered transaction &#123;&#125;"</span>, name(), operatorState.getPendingTransaction());</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				<span class="keyword">if</span> (userContext.isPresent()) &#123;</span><br><span class="line">					finishRecoveringContext(handledTransactions);</span><br><span class="line">					recoveredUserContext = <span class="keyword">true</span>;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> (!recoveredUserContext) &#123;</span><br><span class="line">			LOG.info(<span class="string">"&#123;&#125; - no state to restore"</span>, name());</span><br><span class="line"></span><br><span class="line">			userContext = initializeUserContext();</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">this</span>.pendingCommitTransactions.clear();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//开始事务</span></span><br><span class="line">		currentTransactionHolder = beginTransactionInternal();</span><br><span class="line">		LOG.debug(<span class="string">"&#123;&#125; - started new transaction '&#123;&#125;'"</span>, name(), currentTransactionHolder);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>从上面最后一句可以看到已经开始事务注册了。而最后在kafka011中就会调用以下方法。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">FlinkKafkaProducer011</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">protected</span> KafkaTransactionState <span class="title">beginTransaction</span><span class="params">()</span> <span class="keyword">throws</span> FlinkKafka011Exception </span>&#123;</span><br><span class="line">		<span class="keyword">switch</span> (semantic) &#123;</span><br><span class="line">			<span class="keyword">case</span> EXACTLY_ONCE:</span><br><span class="line">      <span class="comment">//生成一个新的KafkaProducer，可以看到它使用了一个TransactionId</span></span><br><span class="line">				FlinkKafkaProducer&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; producer = createTransactionalProducer();</span><br><span class="line">				producer.beginTransaction();</span><br><span class="line">				<span class="keyword">return</span> <span class="keyword">new</span> KafkaTransactionState(producer.getTransactionalId(), producer);</span><br><span class="line">			<span class="keyword">case</span> AT_LEAST_ONCE:</span><br><span class="line">			<span class="keyword">case</span> NONE:</span><br><span class="line">				<span class="keyword">final</span> KafkaTransactionState currentTransaction = currentTransaction();</span><br><span class="line">				<span class="keyword">if</span> (currentTransaction != <span class="keyword">null</span> &amp;&amp; currentTransaction.producer != <span class="keyword">null</span>) &#123;</span><br><span class="line">					<span class="keyword">return</span> <span class="keyword">new</span> KafkaTransactionState(currentTransaction.producer);</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">return</span> <span class="keyword">new</span> KafkaTransactionState(initNonTransactionalProducer(<span class="keyword">true</span>));</span><br><span class="line">			<span class="keyword">default</span>:</span><br><span class="line">				<span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">"Not implemented semantic"</span>);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">TwoPhaseCommitSinkFunction</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">snapshotState</span><span class="params">(FunctionSnapshotContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">		checkState(currentTransactionHolder != <span class="keyword">null</span>, <span class="string">"bug: no transaction object when performing state snapshot"</span>);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">long</span> checkpointId = context.getCheckpointId();</span><br><span class="line">		LOG.debug(<span class="string">"&#123;&#125; - checkpoint &#123;&#125; triggered, flushing transaction '&#123;&#125;'"</span>, name(), context.getCheckpointId(), currentTransactionHolder);</span><br><span class="line">    <span class="comment">//进行两阶段提交的预提交阶段</span></span><br><span class="line">		preCommit(currentTransactionHolder.handle);</span><br><span class="line">		pendingCommitTransactions.put(checkpointId, currentTransactionHolder);</span><br><span class="line">		LOG.debug(<span class="string">"&#123;&#125; - stored pending transactions &#123;&#125;"</span>, name(), pendingCommitTransactions);</span><br><span class="line"></span><br><span class="line">		currentTransactionHolder = beginTransactionInternal();</span><br><span class="line">		LOG.debug(<span class="string">"&#123;&#125; - started new transaction '&#123;&#125;'"</span>, name(), currentTransactionHolder);</span><br><span class="line"></span><br><span class="line">		state.clear();</span><br><span class="line">		state.add(<span class="keyword">new</span> State&lt;&gt;(</span><br><span class="line">			<span class="keyword">this</span>.currentTransactionHolder,</span><br><span class="line">			<span class="keyword">new</span> ArrayList&lt;&gt;(pendingCommitTransactions.values()),</span><br><span class="line">			userContext));</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>在预提交最后会调用这个方法，其中flush方法是kafka producer的flush代理方法。如果在最后checkErroneous方法中出现问题。就表明这次的提交有问题，需要放弃<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">FlinkKafkaProducer011</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">preCommit</span><span class="params">(KafkaTransactionState transaction)</span> <span class="keyword">throws</span> FlinkKafka011Exception </span>&#123;</span><br><span class="line">		<span class="keyword">switch</span> (semantic) &#123;</span><br><span class="line">			<span class="keyword">case</span> EXACTLY_ONCE:</span><br><span class="line">			<span class="keyword">case</span> AT_LEAST_ONCE:</span><br><span class="line">				flush(transaction);</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			<span class="keyword">case</span> NONE:</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			<span class="keyword">default</span>:</span><br><span class="line">				<span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">"Not implemented semantic"</span>);</span><br><span class="line">		&#125;</span><br><span class="line">    <span class="comment">//检查这次提交有没有问题</span></span><br><span class="line">		checkErroneous();</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure></p>
<p>最后就是两阶段协议的正式提交阶段了，由于消息的延迟，可能存在当前checkpoint之前的事务还没进行commit，所以要进行一次确认。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">TwoPhaseCommitSinkFunction</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">notifyCheckpointComplete</span><span class="params">(<span class="keyword">long</span> checkpointId)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">		Iterator&lt;Map.Entry&lt;Long, TransactionHolder&lt;TXN&gt;&gt;&gt; pendingTransactionIterator = pendingCommitTransactions.entrySet().iterator();</span><br><span class="line">		checkState(pendingTransactionIterator.hasNext(), <span class="string">"checkpoint completed, but no transaction pending"</span>);</span><br><span class="line">		Throwable firstError = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">//判断之前是否有还未提交的事务</span></span><br><span class="line">		<span class="keyword">while</span> (pendingTransactionIterator.hasNext()) &#123;</span><br><span class="line">			Map.Entry&lt;Long, TransactionHolder&lt;TXN&gt;&gt; entry = pendingTransactionIterator.next();</span><br><span class="line">			Long pendingTransactionCheckpointId = entry.getKey();</span><br><span class="line">			TransactionHolder&lt;TXN&gt; pendingTransaction = entry.getValue();</span><br><span class="line">			<span class="keyword">if</span> (pendingTransactionCheckpointId &gt; checkpointId) &#123;</span><br><span class="line">				<span class="keyword">continue</span>;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			LOG.info(<span class="string">"&#123;&#125; - checkpoint &#123;&#125; complete, committing transaction &#123;&#125; from checkpoint &#123;&#125;"</span>,</span><br><span class="line">				name(), checkpointId, pendingTransaction, pendingTransactionCheckpointId);</span><br><span class="line"></span><br><span class="line">			logWarningIfTimeoutAlmostReached(pendingTransaction);</span><br><span class="line">			<span class="keyword">try</span> &#123;</span><br><span class="line">				commit(pendingTransaction.handle);</span><br><span class="line">			&#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">				<span class="keyword">if</span> (firstError == <span class="keyword">null</span>) &#123;</span><br><span class="line">					firstError = t;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			LOG.debug(<span class="string">"&#123;&#125; - committed checkpoint transaction &#123;&#125;"</span>, name(), pendingTransaction);</span><br><span class="line"></span><br><span class="line">			pendingTransactionIterator.remove();</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> (firstError != <span class="keyword">null</span>) &#123;</span><br><span class="line">			<span class="keyword">throw</span> <span class="keyword">new</span> FlinkRuntimeException(<span class="string">"Committing one of transactions failed, logging first encountered failure"</span>,</span><br><span class="line">				firstError);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里的commit也是kafka producer的commit代理方法.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">FlinkKafkaProducer011</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">commit</span><span class="params">(KafkaTransactionState transaction)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (transaction.isTransactional()) &#123;</span><br><span class="line">			<span class="keyword">try</span> &#123;</span><br><span class="line">				transaction.producer.commitTransaction();</span><br><span class="line">			&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">				recycleTransactionalProducer(transaction.producer);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://flink.apache.org/features/2018/03/01/end-to-end-exactly-once-apache-flink.html" target="_blank" rel="noopener">https://flink.apache.org/features/2018/03/01/end-to-end-exactly-once-apache-flink.html</a></p>
<p><a href="https://blog.csdn.net/lisenyeahyeah/article/details/90288231" target="_blank" rel="noopener">https://blog.csdn.net/lisenyeahyeah/article/details/90288231</a></p>
<p><a href="https://www.confluent.io/blog/transactions-apache-kafka/" target="_blank" rel="noopener">https://www.confluent.io/blog/transactions-apache-kafka/</a></p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2020/06/17/《Streaming-Systems》——-Watermark与Window/">《Streaming-Systems》—— WaterMark与Window</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-06-17
        </span></div>
    </header>

    <div class="post-content"><h2 id="全文纲要"><a href="#全文纲要" class="headerlink" title="全文纲要"></a>全文纲要</h2><p>由于 watermark 和 window 的概念在前几篇文章中讲过了，所以这篇文章并不会对很多基本概念再次进行赘述。</p>
<h2 id="Processing-Time-Watermarks"><a href="#Processing-Time-Watermarks" class="headerlink" title="Processing-Time Watermarks"></a>Processing-Time Watermarks</h2>
        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2020/01/01/《Streaming-Systems》——-The-What-Where-When-and-How-of-Data-Processing/">《Streaming Systems》—— The What, Where, When, and How of Data Processing</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-01-01
        </span></div>
    </header>

    <div class="post-content"><h2 id="本文要讲什么？"><a href="#本文要讲什么？" class="headerlink" title="本文要讲什么？"></a>本文要讲什么？</h2><p>前一篇《Streaming Systems》主要讲述了流系统该如何超过批系统，以及两个重要的概念–事件时间（event time）和窗口（window）。而在这一篇文章中将会介绍三个新的概念。</p>
<ol>
<li><p>触发器（triggers)</p>
</li>
<li><p>水位线（watermarks）</p>
</li>
<li><p>accumulation （不知道怎么翻，就用英语了）</p>
</li>
</ol>
<p>而为了更加形象得介绍这三个概念，将会通过用四个问题的形式来进行。这四个问题对于处理无限数据集的情景来说都是非常重要的。</p>
<ol>
<li><p>什么样的数据才会被计算？（What results are calculated？）</p>
</li>
<li><p>事件时间的结果将在哪里进行计算？（Where in event time are results calculated?）</p>
</li>
<li><p>依据系统时间计算的结果该在什么时候生成？（When in processing time are results materialized?）</p>
</li>
<li><p>How do refinements of results relate? （如何关联每一个结果的改进？）</p>
</li>
</ol>
          <div class="read-more">
            <a href="/2020/01/01/《Streaming-Systems》——-The-What-Where-When-and-How-of-Data-Processing/" class="read-more-link">阅读更多</a>
          </div>
        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2019/11/12/Flink-Async-I-O/">Flink Async I/O</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-11-12
        </span></div>
    </header>

    <div class="post-content"><h1 id="为什么需要Flink-Async-I-O"><a href="#为什么需要Flink-Async-I-O" class="headerlink" title="为什么需要Flink Async I/O"></a>为什么需要Flink Async I/O</h1><p><img src="https://ci.apache.org/projects/flink/flink-docs-release-1.9/fig/async_io.svg" alt="Async I/O与传统I/O的区别"></p>
<p>对于传统的阻塞I/O来说，每次和数据库进行一次就会被堵塞，下一次的I/O请求得等到上一次的完成才能发出，这对于流式系统的性能影响是很大的。</p>
<p>而如果像图中所示，通过异步I/O的方式，并发得发出多个请求，这样就可以把一次请求的时间平摊到多个请求中了。</p>
<!-- # Flink Async I/O 架构 -->
<!-- ![架构图](https://cwiki.apache.org/confluence/download/attachments/65870673/future-wait-operator.jpg?version=1&modificationDate=1474192093000&api=v2)

![AsyncCollectorBuffer架构图](https://cwiki.apache.org/confluence/download/attachments/65870673/async-task-buffer.jpg?version=1&modificationDate=1474192804000&api=v2) -->
          <div class="read-more">
            <a href="/2019/11/12/Flink-Async-I-O/" class="read-more-link">阅读更多</a>
          </div>
        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2019/10/04/《Streaming-Systems》之《Streaming-101》/">《Streaming Systems》之《Streaming 101》</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-10-04
        </span></div>
    </header>

    <div class="post-content"><p>这是《Streaming Systems》系列的第一篇。</p>
<h2 id="《Streaming-101》讲了什么"><a href="#《Streaming-101》讲了什么" class="headerlink" title="《Streaming 101》讲了什么"></a>《Streaming 101》讲了什么</h2><p>作为介绍 Streaming Systems 的开篇，自然会先介绍什么是流式系统，然后说明流处理引擎为了超过批处理引擎应该做到什么，之后讲到了 Event Time 和 Processing Time 的区别，最后以常见的数据处理模式作为结尾。</p>
          <div class="read-more">
            <a href="/2019/10/04/《Streaming-Systems》之《Streaming-101》/" class="read-more-link">阅读更多</a>
          </div>
        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2019/09/28/Flink-Window-初探/">Flink Window 初探</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-09-28
        </span></div>
    </header>

    <div class="post-content"><p>在这篇文章中，我会谈谈在 Flink 中 Window 是什么，再以一个简单的例子分析一下 Window 的源码。</p>
<p>注：本文的代码基于Flink 1.9.0，且源码只涉及 TumblingEventTimeWindow</p>
          <div class="read-more">
            <a href="/2019/09/28/Flink-Window-初探/" class="read-more-link">阅读更多</a>
          </div>
        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/2019/02/17/程序次序规则/">程序次序规则</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-02-17
        </span></div>
    </header>

    <div class="post-content"><h2 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h2><p>在学习Java内存模型的时候，有一个先行发生原则，也就是happens-before，其中第一条</p>
<blockquote>
<p>If x and y are actions of the same thread and x comes before y in program order, then hb(x, y)</p>
</blockquote>
<p>这句话的意思是如果在一个线程里里面，x语句书写的顺序在y语句前面，那么x语句就会先行发生于y语句。这也是我们常说的程序次序规则(Program Order Rule)。</p>
          <div class="read-more">
            <a href="/2019/02/17/程序次序规则/" class="read-more-link">阅读更多</a>
          </div>
        </div></article>
      <nav class="pagination"></nav></section></div></div>
      </main>

      <footer id="footer" class="footer"><div class="social-links"><a href="mailto:AT-Fieldless@outlook.com" class="iconfont icon-email" title="email"></a>
        <a href="https://github.com/AT-Fieldless" class="iconfont icon-github" title="github"></a>
        <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    </div><div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">&copy;2015 - 2020<span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">thirteen</span>
  </span>
</div>
</footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div><script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  <script type="text/javascript" src="/js/src/even.js?v=2.11.0"></script>
</body>
</html>
